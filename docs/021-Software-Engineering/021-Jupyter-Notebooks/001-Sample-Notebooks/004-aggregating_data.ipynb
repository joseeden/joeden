{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/joseeden/joeden/blob/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/001-Sample-Notebooks/004-aggregating_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walmart Dataset Overview  \n",
    "\n",
    "The dataset contains weekly sales data for Walmart stores, including:  \n",
    "\n",
    "- Store ID and type  \n",
    "- Weekly sales and department IDs  \n",
    "- Holiday week indicator  \n",
    "- Average temperature and fuel prices  \n",
    "- National unemployment rate  \n",
    "\n",
    "The dataset can be downloaded here: [sales_subset.csv](@site/assets/datasets/pandas-aggregating-data/sales_subset.csv)\n",
    "\n",
    "Sample rows:  \n",
    "\n",
    "| Store | Sales    | Dept | Holiday | Temp (Â°C) | Fuel Price (USD/L) | Unemployment |\n",
    "|-------|----------|------|---------|-----------|---------------------|--------------|\n",
    "|   1   | 24924.50 |   1  |    0    |   5.73    |         0.68        |     8.11     |\n",
    "|   1   | 21827.90 |   1  |    0    |   8.06    |         0.69        |     8.11     |\n",
    "|   1   | 57258.43 |   1  |    0    |  16.82    |         0.72        |     7.81     |\n",
    "|   1   | 17413.94 |   1  |    0    |  22.53    |         0.75        |     7.81     |\n",
    "|   1   | 17558.09 |   1  |    0    |  27.05    |         0.71        |     7.81     |\n",
    "|   1   | 16333.14 |   1  |    0    |  27.17    |         0.71        |     7.79     | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Median\n",
    "\n",
    "Print information about the columns in sales using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use URL , so that notebook can be ran from Google Colab without downloading csv file\n",
    "url = 'https://raw.githubusercontent.com/joseeden/joeden/refs/heads/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/000-Sample-Datasets/aggregating-data-using-pandas/sales_subset.csv'\n",
    "sales = pd.read_csv(url)\n",
    "\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information about the columns in sales using `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            10774 non-null  int64  \n",
      " 1   store                 10774 non-null  int64  \n",
      " 2   type                  10774 non-null  object \n",
      " 3   department            10774 non-null  int64  \n",
      " 4   date                  10774 non-null  object \n",
      " 5   weekly_sales          10774 non-null  float64\n",
      " 6   is_holiday            10774 non-null  bool   \n",
      " 7   temperature_c         10774 non-null  float64\n",
      " 8   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 9   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the mean of the `weekly_sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843.95014850566\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"weekly_sales\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the median of the `weekly_sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates \n",
    "\n",
    "Print the maximum of the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the minimum of the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Summaries  \n",
    "\n",
    "Sometimes, you need custom functions to summarize your data beyond what pandas and NumPy offer.  \n",
    "The `.agg()` method allows custom functions to a DataFrame, even across multiple columns, for efficient aggregation.  \n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "df['column'].agg(function)\n",
    "```  \n",
    "\n",
    "In this exercise, the custom function calculates the \"IQR\" (inter-quartile range), which is the difference between the 75th and 25th percentiles. Using this function, print the IQR of the `temperature_c` column of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[\"temperature_c\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the column selection to use the custom `iqr` function with `.agg()` to print the IQR of these in order:\n",
    "\n",
    "- `temperature_c`\n",
    "- `fuel_price_usd_per_l`\n",
    "- `unemployment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\n",
    "    \"temperature_c\", \n",
    "    \"fuel_price_usd_per_l\",\n",
    "    \"unemployment\"\n",
    "]].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the aggregation functions called by `.agg()` in order:\n",
    "\n",
    "- `iqr`\n",
    "- `np.median`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joseeden\\AppData\\Local\\Temp\\ipykernel_28160\\1977351458.py:9: FutureWarning: The provided callable <function median at 0x000001C3BC841800> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  ]].agg([iqr, np.median]))\n",
      "C:\\Users\\joseeden\\AppData\\Local\\Temp\\ipykernel_28160\\1977351458.py:9: FutureWarning: The provided callable <function median at 0x000001C3BC841800> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  ]].agg([iqr, np.median]))\n",
      "C:\\Users\\joseeden\\AppData\\Local\\Temp\\ipykernel_28160\\1977351458.py:9: FutureWarning: The provided callable <function median at 0x000001C3BC841800> is currently using Series.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  ]].agg([iqr, np.median]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\n",
    "    \"temperature_c\", \n",
    "    \"fuel_price_usd_per_l\",\n",
    "    \"unemployment\"\n",
    "]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative Statistics  \n",
    "\n",
    "Cumulative statistics help track data over time. In this exercise, you'll calculate the cumulative sum and maximum of a department's weekly sales to find the total sales so far and the highest weekly sales so far.  \n",
    "\n",
    "Create the a DataFrame `sales_1_1` with sales data for department 1 of store 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/joseeden/joeden/refs/heads/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/000-Sample-Datasets/aggregating-data-using-pandas/sales_subset_store_1.csv'\n",
    "sales_1_1 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort `sales_1_1` by date. Get the cumulative sum of `weekly_sales`, then add as a new column called `cum_weekly_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "print(sales_1_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the cumulative max of `weekly_sales`, then add as a new column called `cum_max_sales`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "print(sales_1_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the three new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
