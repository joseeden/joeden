{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/joseeden/joeden/blob/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/004-aggregating_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walmart Dataset Overview  \n",
    "\n",
    "The dataset contains weekly sales data for Walmart stores, including:  \n",
    "\n",
    "- Store ID and type  \n",
    "- Weekly sales and department IDs  \n",
    "- Holiday week indicator  \n",
    "- Average temperature and fuel prices  \n",
    "- National unemployment rate  \n",
    "\n",
    "The dataset can be downloaded here: [sales_subset.csv](@site/assets/datasets/pandas-aggregating-data/sales_subset.csv)\n",
    "\n",
    "Sample rows:  \n",
    "\n",
    "| Store | Sales    | Dept | Holiday | Temp (Â°C) | Fuel Price (USD/L) | Unemployment |\n",
    "|-------|----------|------|---------|-----------|---------------------|--------------|\n",
    "|   1   | 24924.50 |   1  |    0    |   5.73    |         0.68        |     8.11     |\n",
    "|   1   | 21827.90 |   1  |    0    |   8.06    |         0.69        |     8.11     |\n",
    "|   1   | 57258.43 |   1  |    0    |  16.82    |         0.72        |     7.81     |\n",
    "|   1   | 17413.94 |   1  |    0    |  22.53    |         0.75        |     7.81     |\n",
    "|   1   | 17558.09 |   1  |    0    |  27.05    |         0.71        |     7.81     |\n",
    "|   1   | 16333.14 |   1  |    0    |  27.17    |         0.71        |     7.79     | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Median\n",
    "\n",
    "Print information about the columns in sales using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use URL , so that notebook can be ran from Google Colab without downloading csv file\n",
    "url = 'https://raw.githubusercontent.com/joseeden/joeden/refs/heads/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/000-Sample-Datasets/aggregating-data-using-pandas/sales_subset.csv'\n",
    "sales = pd.read_csv(url)\n",
    "\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information about the columns in sales using `info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the mean of the `weekly_sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales[\"weekly_sales\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the median of the `weekly_sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates \n",
    "\n",
    "Print the maximum of the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the minimum of the date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Summaries  \n",
    "\n",
    "Sometimes, you need custom functions to summarize your data beyond what pandas and NumPy offer.  \n",
    "The `.agg()` method allows custom functions to a DataFrame, even across multiple columns, for efficient aggregation.  \n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "df['column'].agg(function)\n",
    "```  \n",
    "\n",
    "In this exercise, the custom function calculates the \"IQR\" (inter-quartile range), which is the difference between the 75th and 25th percentiles. Using this function, print the IQR of the `temperature_c` column of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[\"temperature_c\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the column selection to use the custom `iqr` function with `.agg()` to print the IQR of these in order:\n",
    "\n",
    "- `temperature_c`\n",
    "- `fuel_price_usd_per_l`\n",
    "- `unemployment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\n",
    "    \"temperature_c\", \n",
    "    \"fuel_price_usd_per_l\",\n",
    "    \"unemployment\"\n",
    "]].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the aggregation functions called by `.agg()` in order:\n",
    "\n",
    "- `iqr`\n",
    "- `np.median`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[[\n",
    "    \"temperature_c\", \n",
    "    \"fuel_price_usd_per_l\",\n",
    "    \"unemployment\"\n",
    "]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative Statistics  \n",
    "\n",
    "Cumulative statistics help track data over time. In this exercise, you'll calculate the cumulative sum and maximum of a department's weekly sales to find the total sales so far and the highest weekly sales so far.  \n",
    "\n",
    "Create the a DataFrame `sales_1_1` with sales data for department 1 of store 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/joseeden/joeden/refs/heads/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/000-Sample-Datasets/aggregating-data-using-pandas/sales_subset_store_1.csv'\n",
    "sales = pd.read_csv(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
