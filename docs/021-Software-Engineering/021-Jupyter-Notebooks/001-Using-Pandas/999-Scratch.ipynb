{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch \n",
    "\n",
    "This file is used for short one-off tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/joseeden/joeden/blob/master/docs/021-Software-Engineering/021-Jupyter-Notebooks/001-Using-Pandas/999-Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"Ted\", \"Stella\", \"Ted\", \"Robin\", \"Ted\", \"Stella\"],\n",
    "    \"Breed\": [\"Labrador\", \"Golden Retriever\", \"Chow Chow\", \"Poodle\", \"Labrador\", \"Golden Retriever\"],\n",
    "    \"Color\": [\"Black\", \"Golden\", \"Brown\", \"White\", \"Black\", \"Golden\"],\n",
    "    \"Visit Date\": [\"2023-01-10\", \"2023-01-12\", \"2023-01-15\", \"2023-01-18\", \"2023-01-20\", \"2023-01-22\"],\n",
    "    \"Weight\": [30, 25, 28, 20, 32, 26]  # Add weights in kilograms\n",
    "}\n",
    "\n",
    "dogs = pd.DataFrame(data)\n",
    "print(dogs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby(\"Breed\")[\"Name\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby(\"Color\").agg({\n",
    "        \"Name\": \"nunique\",\n",
    "        \"Visit Date\": \"count\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby([\"Color\", \"Breed\"])[\"Name\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.groupby([\"Color\", \"Breed\"]).agg({\n",
    "        \"Name\": \"nunique\",\n",
    "    \"Visit Date\": \"count\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"Weight\", index=\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dogs.pivot_table(values=\"Weight\", index=\"Color\", aggfunc=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"Weight\", index=\"Color\", aggfunc=[np.mean, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"Weight\", index=\"Color\", columns=\"Breed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"Weight\", index=\"Color\", columns=\"Breed\", fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values=\"Weight\", index=Color\", columns=\"Breed\", fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'breed': ['Labrador', 'Chow Chow', 'Poodle', 'Labrador', 'Beagle', 'Chihuahua', \n",
    "              'Poodle', 'Labrador', 'Beagle', 'Chow Chow'],\n",
    "    'color': ['Brown', 'Tan', 'White', 'Black', 'Brown', 'Grey', \n",
    "              'Brown', 'Black', 'White', 'Tan'],\n",
    "    'age': [3, 4, 2, 7, 5, 1, 3, 6, 4, 5],\n",
    "    'weight': [25, 18, 12, 30, 10, 3, 20, 28, 12, 17],\n",
    "    'date_of_birth': ['2016-01-01', '2015-06-15', '2017-03-20', '2014-09-10', '2015-12-01', '2018-05-05',\n",
    "                      '2017-03-20', '2014-09-10', '2015-12-01', '2015-06-15'],\n",
    "}\n",
    "\n",
    "dogs = pd.DataFrame(data)\n",
    "dogs['height'] = [23, 20, 20, 23, 21, 18, 22, 24, 21, 19]  # Adding height column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.pivot_table(values='height', index='breed', columns='color', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.loc[dogs['breed'] == 'Poodle', ['height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs.mean(axis=\"index\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ward            alderman                          address    zip\n",
      "0    1  Proco \"Joe\" Moreno        2058 NORTH WESTERN AVENUE  60647\n",
      "1    2       Brian Hopkins       1400 NORTH  ASHLAND AVENUE  60622\n",
      "2    3          Pat Dowell          5046 SOUTH STATE STREET  60609\n",
      "3    4    William D. Burns  435 EAST 35TH STREET, 1ST FLOOR  60616\n",
      "4    5  Leslie A. Hairston            2325 EAST 71ST STREET  60649\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iid  cid invoice_date  total\n",
      "0  101    1   2019-01-10    100\n",
      "1  102    2   2019-01-15    200\n",
      "2  103    3   2019-01-20    150\n",
      "0  104    4   2019-02-05    170\n",
      "1  105    5   2019-02-12    250\n",
      "2  106    6   2019-02-18    300\n",
      "3  107    7   2019-02-25    190\n",
      "0  108    8   2019-03-03    210\n",
      "1  109    9   2019-03-10    280\n",
      "2  110   10   2019-03-17    190\n",
      "3  111   11   2019-03-24    240\n",
      "4  112   12   2019-03-30    270\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Invoice data for three months\n",
    "inv_jan = pd.DataFrame([\n",
    "    [101, 1, '2019-01-10', 100], \n",
    "    [102, 2, '2019-01-15', 200], \n",
    "    [103, 3, '2019-01-20', 150]\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total'])\n",
    "\n",
    "inv_feb = pd.DataFrame([\n",
    "    [104, 4, '2019-02-05', 170], \n",
    "    [105, 5, '2019-02-12', 250], \n",
    "    [106, 6, '2019-02-18', 300], \n",
    "    [107, 7, '2019-02-25', 190]\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total'])\n",
    "\n",
    "inv_mar = pd.DataFrame([\n",
    "    [108, 8, '2019-03-03', 210], \n",
    "    [109, 9, '2019-03-10', 280], \n",
    "    [110, 10, '2019-03-17', 190], \n",
    "    [111, 11, '2019-03-24', 240], \n",
    "    [112, 12, '2019-03-30', 270]\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total'])\n",
    "\n",
    "# Concatenating tables\n",
    "combined = pd.concat([inv_jan, inv_feb, inv_mar])\n",
    "print(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iid  cid invoice_date  total\n",
      "0   101    1   2019-01-10    100\n",
      "1   102    2   2019-01-15    200\n",
      "2   103    3   2019-01-20    150\n",
      "3   104    4   2019-02-05    170\n",
      "4   105    5   2019-02-12    250\n",
      "5   106    6   2019-02-18    300\n",
      "6   107    7   2019-02-25    190\n",
      "7   108    8   2019-03-03    210\n",
      "8   109    9   2019-03-10    280\n",
      "9   110   10   2019-03-17    190\n",
      "10  111   11   2019-03-24    240\n",
      "11  112   12   2019-03-30    270\n"
     ]
    }
   ],
   "source": [
    "combined_reset = pd.concat([inv_jan, inv_feb, inv_mar], ignore_index=True)\n",
    "print(combined_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       iid  cid invoice_date  total\n",
      "Jan 0  101    1   2019-01-10    100\n",
      "    1  102    2   2019-01-15    200\n",
      "    2  103    3   2019-01-20    150\n",
      "Feb 0  104    4   2019-02-05    170\n",
      "    1  105    5   2019-02-12    250\n",
      "    2  106    6   2019-02-18    300\n",
      "    3  107    7   2019-02-25    190\n",
      "Mar 0  108    8   2019-03-03    210\n",
      "    1  109    9   2019-03-10    280\n",
      "    2  110   10   2019-03-17    190\n",
      "    3  111   11   2019-03-24    240\n",
      "    4  112   12   2019-03-30    270\n"
     ]
    }
   ],
   "source": [
    "combined_keys = pd.concat(\n",
    "              [inv_jan, inv_feb, inv_mar], \n",
    "              ignore_index=False,\n",
    "              keys=['Jan', 'Feb', 'Mar'])\n",
    "print(combined_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iid  cid invoice_date  total billing_country\n",
      "0  101    1   2019-01-10    100             NaN\n",
      "1  102    2   2019-01-15    200             NaN\n",
      "2  103    3   2019-01-20    150             NaN\n",
      "0  104    4   2019-02-05    170              US\n",
      "1  105    5   2019-02-12    250              CA\n",
      "2  106    6   2019-02-18    300              UK\n",
      "3  107    7   2019-02-25    190              FR\n"
     ]
    }
   ],
   "source": [
    "inv_feb = pd.DataFrame([\n",
    "    [104, 4, '2019-02-05', 170, 'US'], \n",
    "    [105, 5, '2019-02-12', 250, 'CA'], \n",
    "    [106, 6, '2019-02-18', 300, 'UK'], \n",
    "    [107, 7, '2019-02-25', 190, 'FR']\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total', 'billing_country'])\n",
    "\n",
    "combined_diff = pd.concat([inv_jan, inv_feb])\n",
    "print(combined_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  billing_country  cid  iid invoice_date  total\n",
      "0             NaN    1  101   2019-01-10    100\n",
      "1             NaN    2  102   2019-01-15    200\n",
      "2             NaN    3  103   2019-01-20    150\n",
      "0              US    4  104   2019-02-05    170\n",
      "1              CA    5  105   2019-02-12    250\n",
      "2              UK    6  106   2019-02-18    300\n",
      "3              FR    7  107   2019-02-25    190\n"
     ]
    }
   ],
   "source": [
    "sort_diff = pd.concat([inv_jan, inv_feb], sort=True)\n",
    "print(sort_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iid  cid invoice_date  total\n",
      "0  101    1   2019-01-10    100\n",
      "1  102    2   2019-01-15    200\n",
      "2  103    3   2019-01-20    150\n",
      "0  104    4   2019-02-05    170\n",
      "1  105    5   2019-02-12    250\n",
      "2  106    6   2019-02-18    300\n",
      "3  107    7   2019-02-25    190\n"
     ]
    }
   ],
   "source": [
    "combined_inner = pd.concat([inv_jan, inv_feb], join=\"inner\")\n",
    "print(combined_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tracks = pd.DataFrame([\n",
    "    [1, 'Song A'], \n",
    "    [2, 'Song B'], \n",
    "    [3, 'Song C']\n",
    "], columns=['tid', 'track'])\n",
    "\n",
    "specs = pd.DataFrame([\n",
    "    [1, 'MP3'], \n",
    "    [2, 'FLAC'], \n",
    "    [2, 'WAV'], \n",
    "    [3, 'AAC']\n",
    "], columns=['tid', 'format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in right dataset; not a one-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone_to_one\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:813\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_validate_kwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:1657\u001b[0m, in \u001b[0;36m_MergeOperation._validate_validate_kwd\u001b[1;34m(self, validate)\u001b[0m\n\u001b[0;32m   1653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1654\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in left dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1655\u001b[0m         )\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_unique:\n\u001b[1;32m-> 1657\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in right dataset; not a one-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1659\u001b[0m         )\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m validate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_to_many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1:m\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left_unique:\n",
      "\u001b[1;31mMergeError\u001b[0m: Merge keys are not unique in right dataset; not a one-to-one merge"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(tracks, specs, on='tid', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tid   track format\n",
      "0    1  Song A    MP3\n",
      "1    2  Song B   FLAC\n",
      "2    2  Song B    WAV\n",
      "3    3  Song C    AAC\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(tracks, specs, on='tid', validate='one_to_many')\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_feb = pd.DataFrame([\n",
    "    [8, 1, '2019-02-10', 100], \n",
    "    [9, 2, '2019-02-15', 200]\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total']).set_index('iid')\n",
    "\n",
    "inv_mar = pd.DataFrame([\n",
    "    [9, 3, '2019-03-05', 250],  # Duplicate iid=9\n",
    "    [10, 4, '2019-03-10', 300]\n",
    "], columns=['iid', 'cid', 'invoice_date', 'total']).set_index('iid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Indexes have overlapping values: Index([9], dtype='int64', name='iid')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minv_feb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_mar\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:671\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjs:\n\u001b[0;32m    670\u001b[0m     indexers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax, new_labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m):\n\u001b[0;32m    672\u001b[0m         \u001b[38;5;66;03m# ::-1 to convert BlockManager ax to DataFrame ax\u001b[39;00m\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis:\n\u001b[0;32m    674\u001b[0m             \u001b[38;5;66;03m# Suppress reindexing on concat axis\u001b[39;00m\n\u001b[0;32m    675\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:702\u001b[0m, in \u001b[0;36m_Concatenator.new_axes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[1;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_comb_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:703\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_axes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Index]:\n\u001b[0;32m    701\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_result_dim()\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 703\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concat_axis\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comb_axis(i)\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)\n\u001b[0;32m    705\u001b[0m     ]\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:766\u001b[0m, in \u001b[0;36m_Concatenator._get_concat_axis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     concat_axis \u001b[38;5;241m=\u001b[39m _make_concat_multiindex(\n\u001b[0;32m    763\u001b[0m         indexes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m    764\u001b[0m     )\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat_axis\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\concat.py:774\u001b[0m, in \u001b[0;36m_Concatenator._maybe_check_integrity\u001b[1;34m(self, concat_index)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m concat_index\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    773\u001b[0m     overlap \u001b[38;5;241m=\u001b[39m concat_index[concat_index\u001b[38;5;241m.\u001b[39mduplicated()]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexes have overlapping values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverlap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Indexes have overlapping values: Index([9], dtype='int64', name='iid')"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([inv_feb, inv_mar], verify_integrity=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cid invoice_date  total\n",
      "iid                         \n",
      "8      1   2019-02-10    100\n",
      "9      2   2019-02-15    200\n",
      "9      3   2019-03-05    250\n",
      "10     4   2019-03-10    300\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat([inv_feb, inv_mar], verify_integrity=False)\n",
    "print(combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
